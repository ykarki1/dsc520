---
title: 'Week 11: Machine Learning'
author: "Yograj Karki"
date: "6/5/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Loading packages and working directories
```{r }
#Packages
library(ggplot2)
library(plyr)
library(dplyr)
library(tidyverse)
library(factoextra)
library(cluster) 
library(class)

  setwd("~/MSDS/DSC520/dsc520")
```

## Loading the data
```{r}
binary_df <- read.csv("data/binary-classifier-data.csv")
trinary_df <- read.csv("data/trinary-classifier-data.csv")
head(binary_df)
head(trinary_df)
```


# Scatter plot binary classifier
```{r}

library(ggvis)
binary_df %>% ggvis(~x, ~y, fill = ~label) %>% layer_points()

```

# Scatter plot trinary classifier data
```{r}
trinary_df %>% ggvis(~x, ~y, fill = ~label) %>% layer_points()

```
```{r}
library(kknn)
```


# For k nearest neighbors algorithm
```{r}
# Generate a random number that is 80% of the total number of rows in data set.
set.seed(42)
# Random sampling
random_binary <- sample(1:nrow(binary_df), 0.8 * nrow(binary_df))
random_trinary <- sample(1:nrow(trinary_df), 0.8*nrow(trinary_df))


#the normalization function is created
normalized <-function(x) { (x -min(x))/(max(x)-min(x)) }
```


## Run normalization on 2 columns of dataset because they are the predictors
```{r}
binary_df_norm <- as.data.frame(lapply(binary_df[,c(2,3)], normalized))
summary(binary_df_norm)
```

## Splitting training and testing data

```{r}
#Binary
train_binary <- binary_df[random_binary,]
test_binary <- trinary_df[-random_binary,]
#Trinary
train_trinary <- trinary_df[random_trinary,] 
test_trinary <- trinary_df[-random_trinary,] 


# Creating separate dataframe for our target
train_binary_labels <- binary_df[random_binary,1]
test_binary_labels <-binary_df[-random_binary,1]
train_trinary_labels <- trinary_df[random_trinary,1]
test_trinary_labels <-trinary_df[-random_trinary,1]
```

## Fit a k nearest neighborsâ€™ model for each dataset for k=3, k=5, k=10, k=15, k=20, and k=25. Compute the accuracy of the resulting models for each value of k. Plot the results in a graph where the x-axis is the different values of k and the y-axis is the accuracy of the model.

## Running a for-loop for each value of k

```{r}
# k = 3
knn_model_3 <- knn(train_binary, test_binary, cl = train_binary_labels, k = 3)
acc_3 <- 100 * sum(test_binary_labels == knn_model_3)/NROW(test_binary_labels)
acc_3
```
```{r}

confusionMatrix(table(knn_model_3, test_binary_labels))
```







```{r}
# Formula for accuracy
accuracy <- function(x){
    sum(diag(x)/(sum(rowSums(x))))*100
}
# Initiating the loop
val <- c(3,5,10,15,20,25)
for (i in val){ 
  knn_model <-  knn(train = train_binary, test=test_binary,
                    cl= train_binary_labels, k=i)
  # make "predictions" with knn model
  predtrn = predict(knn_model, test_binary, type = "class")
  # Confusion matrix
  confusionMatrix(predtrn, test_binary$default)

}
```

```{r}
i=3                         # declaration to initiate for loop
k.optm=1   # declaration to initiate for loop
val <- c(3,5,10,15,20,25)
for (i in val){ 
  knn.mod <-  knn(train=train_binary, test=test_binary, cl=train_binary_labels, k=i)
  k.optm[i] <- 100 * sum(train_binary_labels == knn.mod)/NROW(train_binary_labels)
  k=i  
  cat(k,'=',k.optm[i],'\n')       # to print % accuracy 
}
```


