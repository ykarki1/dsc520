---
title: 'Week 11: Machine Learning'
author: "Yograj Karki"
date: "6/5/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Loading packages and working directories
```{r message= F, warning= F}
#Packages
library(ggplot2)
library(plyr)
library(dplyr)
library(tidyverse)
library(factoextra)
library(cluster)
library(caret)
library(class)

  setwd("~/MSDS/DSC520/dsc520")
```

## Loading the data
```{r}
binary_df <- read.csv("data/binary-classifier-data.csv")
trinary_df <- read.csv("data/trinary-classifier-data.csv")

binary_df$label <- as.factor(binary_df$label)
trinary_df$label <- as.factor(trinary_df$label)

head(binary_df)
head(trinary_df)
```


# Scatter plot binary classifier
```{r}

library(ggvis)
binary_df %>% ggvis(~x, ~y, fill = ~label) %>% layer_points()

```

# Scatter plot trinary classifier data
```{r}
trinary_df %>% ggvis(~x, ~y, fill = ~label) %>% layer_points()

```


# k nearest neighbors algorithm
## Data preparation
```{r}
# Generate a random number that is 80% of the total number of rows in data set.
set.seed(42)
# Random sampling
random_binary <- sample(1:nrow(binary_df), 0.8 * nrow(binary_df))
random_trinary <- sample(1:nrow(trinary_df), 0.8*nrow(trinary_df))
```


## Splitting training and testing data
```{r}
#Binary
train_binary <- binary_df[random_binary,]
test_binary <- trinary_df[-random_binary,]
#Trinary
train_trinary <- trinary_df[random_trinary,] 
test_trinary <- trinary_df[-random_trinary,] 


# Creating separate dataframe for our target
train_binary_labels <- binary_df[random_binary,1]
test_binary_labels <-binary_df[-random_binary,1]
train_trinary_labels <- trinary_df[random_trinary,1]
test_trinary_labels <-trinary_df[-random_trinary,1]
```

## Fit a k nearest neighborsâ€™ model for each dataset for k=3, k=5, k=10, k=15, k=20, and k=25. Compute the accuracy of the resulting models for each value of k. Plot the results in a graph where the x-axis is the different values of k and the y-axis is the accuracy of the model.

## Confusion matrix formula

```{r}
# Formula for confusion matrix
my.statistics <- function(Actual,Predicted) {
  confusion.table <- table(Actual=Actual,Predicted=Predicted)
  output <- list(confusion.table=confusion.table)
  TN <- confusion.table[1]
  FN <- confusion.table[2]
  FP <- confusion.table[3]
  TP <- confusion.table[4]
  output$accuracy <- (TP+TN)/sum(confusion.table)
  output$precission <- (TP)/(TP+FP)
  output$sensitivity <- (TP)/(TP+FN)
  output$specificity <- (TN)/(TN+FP)
  output$FPR <- (FP)/(TN+FP)
  
  return(output)
}
```


```{r}
# k = 3 on Binary data
knn_pred <- knn(train_binary[,c("x","y")], test_binary[,c("x", "y")], cl = train_binary$label, k = 50)

# Accuracy
my.statistics(test_binary$label, knn_pred)

```


```{r}
# Formula for accuracy
# Initiating the loop
val <- c(3,5,10,15,20,25)
for (i in val){ 
  knn_model <-  knn(train_binary[,c("x","y")], test_binary[,c("x", "y")], cl = train_binary$label, k = i)
  


}
```

```{r}
i=3                         # declaration to initiate for loop
k.optm=1   # declaration to initiate for loop
val <- c(3,5,10,15,20,25)
for (i in val){ 
  knn.mod <-  knn(train=train_binary, test=test_binary, cl=train_binary_labels, k=i)
  k.optm[i] <- 100 * sum(train_binary_labels == knn.mod)/NROW(train_binary_labels)
  k=i  
  cat(k,'=',k.optm[i],'\n')       # to print % accuracy 
}
```


